{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a GPT Model with OpenAI\n",
    "\n",
    "This notebook demonstrates the process of fine-tuning a GPT model using the OpenAI API. The steps include loading environment variables, preparing the training data, creating a fine-tuning job, and tracking the job's status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries\n",
    "\n",
    "In this section, we import the necessary libraries for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the OpenAI Client\n",
    "\n",
    "Here, we create an instance of the OpenAI client using our API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the Fine-Tuning Data\n",
    "\n",
    "In this step, we prepare the fine-tuning data by uploading the JSONL file that contains our training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.files.create(file=open(\"academic_ft.jsonl\", \"rb\"), \n",
    "                    purpose=\"fine-tune\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Fine-Tuning Job\n",
    "\n",
    "This is our file id: `file-E0neNSCX1ZL4YnzgkQ5sEphN` (returned at the output of the previous cell). We will use it to create a fine-tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create(training_file=\"file-E0neNSCX1ZL4YnzgkQ5sEphN\",\n",
    "                                model=\"gpt-3.5-turbo\",\n",
    "                                hyperparameters={\"n_epochs\": 3},\n",
    "                                suffix=\"academic-chat\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tracking the Fine-Tuning Job\n",
    "\n",
    "We can track the status of our fine-tuning job to see if it has succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)  # List the fine-tuning jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrieving Job Status\n",
    "\n",
    "Check the 'status' of the fine-tuning job to confirm it has succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-eV6C5YHl1sWUJASxhxxM9FNI\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using the Fine-Tuned Model\n",
    "\n",
    "We can use the fine-tuned model by specifying the model ID. The model ID is available in the fine-tuning job details on our OpenAI dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response from the fine-tuned model will be printed here.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(model=\"ft:gpt-3.5-turbo-0125:personal:academic-chat:APyVOrMR\",\n",
    "                                              messages=[\n",
    "                                                  {\"role\": \"system\", \"content\": \"You are a chatbot that talks in a scientific manner\"},\n",
    "                                                  {\"role\": \"user\", \"content\": \"What can you tell me about the universe?\"}\n",
    "                                                   ],\n",
    "                                                   temperature=0.7)\n",
    "\n",
    "print(completion.choices[0].message.content)  # Print the model's response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
